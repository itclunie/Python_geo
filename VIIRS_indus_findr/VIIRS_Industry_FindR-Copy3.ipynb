{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "startTime = datetime.now() \n",
    "\n",
    "import os, sys\n",
    "import ogr\n",
    "import shapefile as shp\n",
    "from math import ceil\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import Polygon\n",
    "from rtree import index\n",
    "import pandas as pd\n",
    "\n",
    "percLst = []\n",
    "percLst.append(['imports', datetime.now() - startTime ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user inputs\n",
    "# outPath = \"/Users/itclunie/Desktop/ECON/find industry/ChinaVIIRS/\" #folder to dump results\n",
    "# pointfeat = '/Users/itclunie/Desktop/ECON/find industry/ChinaVIIRS/ChinaVIIRS.shp' #starting points\n",
    "outPath = \"/Users/itclunie/Desktop/ECON/find industry/speedTest/\" #folder to dump results\n",
    "pointfeat = '/Users/itclunie/Desktop/ECON/find industry/speedTest/chinaTest.shp' #starting points\n",
    "polyfeat = outPath + 'outGrid2.shp' #name your output grid\n",
    "\n",
    "dateColNum = 5 #in the csv/shapefile, which column is the date column? 1st col is 0, 2nd is 1, etc.\n",
    "gridCutoff = 2 #gridcell has to have n num of months with values to be flagged\n",
    "gridHeight = .02 #.015 = 1.5km\n",
    "gridWidth = .02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeGrid(outputGridfn,xmin,xmax,ymin,ymax,gridHeight,gridWidth):\n",
    "    # convert sys.argv to float\n",
    "    xmin = float(xmin)\n",
    "    xmax = float(xmax)\n",
    "    ymin = float(ymin)\n",
    "    ymax = float(ymax)\n",
    "    gridWidth = float(gridWidth)\n",
    "    gridHeight = float(gridHeight)\n",
    "\n",
    "    # get rows\n",
    "    rows = ceil((ymax-ymin)/gridHeight)\n",
    "    # get columns\n",
    "    cols = ceil((xmax-xmin)/gridWidth)\n",
    "\n",
    "    # start grid cell envelope\n",
    "    ringXleftOrigin = xmin\n",
    "    ringXrightOrigin = xmin + gridWidth\n",
    "    ringYtopOrigin = ymax\n",
    "    ringYbottomOrigin = ymax-gridHeight\n",
    "\n",
    "    # create output file\n",
    "    outDriver = ogr.GetDriverByName('ESRI Shapefile')\n",
    "    if os.path.exists(outputGridfn):\n",
    "        os.remove(outputGridfn)\n",
    "        \n",
    "    outDataSource = outDriver.CreateDataSource(outputGridfn)\n",
    "    outLayer = outDataSource.CreateLayer(outputGridfn,geom_type=ogr.wkbPolygon )\n",
    "    featureDefn = outLayer.GetLayerDefn()\n",
    "\n",
    "    # create grid cells\n",
    "    countcols = 0\n",
    "    while countcols < cols:\n",
    "        countcols += 1\n",
    "\n",
    "        # reset envelope for rows\n",
    "        ringYtop = ringYtopOrigin\n",
    "        ringYbottom =ringYbottomOrigin\n",
    "        countrows = 0\n",
    "\n",
    "        while countrows < rows:\n",
    "            countrows += 1\n",
    "            ring = ogr.Geometry(ogr.wkbLinearRing)\n",
    "            ring.AddPoint(ringXleftOrigin, ringYtop)\n",
    "            ring.AddPoint(ringXrightOrigin, ringYtop)\n",
    "            ring.AddPoint(ringXrightOrigin, ringYbottom)\n",
    "            ring.AddPoint(ringXleftOrigin, ringYbottom)\n",
    "            ring.AddPoint(ringXleftOrigin, ringYtop)\n",
    "            poly = ogr.Geometry(ogr.wkbPolygon)\n",
    "            poly.AddGeometry(ring)\n",
    "\n",
    "            # add new geom to layer\n",
    "            outFeature = ogr.Feature(featureDefn)\n",
    "            outFeature.SetGeometry(poly)\n",
    "            outLayer.CreateFeature(outFeature)\n",
    "            outFeature.Destroy\n",
    "\n",
    "            # new envelope for next poly\n",
    "            ringYtop = ringYtop - gridHeight\n",
    "            ringYbottom = ringYbottom - gridHeight\n",
    "\n",
    "        # new envelope for next poly\n",
    "        ringXleftOrigin = ringXleftOrigin + gridWidth\n",
    "        ringXrightOrigin = ringXrightOrigin + gridWidth\n",
    "\n",
    "    # Close DataSources\n",
    "    outDataSource.Destroy()\n",
    "    \n",
    "def mnthYearChange(instring):\n",
    "    if \"-\" in instring:\n",
    "        dtObj = datetime.strptime(instring, '%Y-%m-%d')\n",
    "    elif \"/\" in instring and len(instring) <= 8:\n",
    "        dtObj = datetime.strptime(instring, '%m/%d/%y')\n",
    "    elif \"/\" in instring and len(instring) >= 8:\n",
    "        dtObj = datetime.strptime(instring, '%m/%d/%Y')\n",
    "    else:\n",
    "        print(\"check date format, did you specify the right column?\")\n",
    "        sys.exit()\n",
    "    return str(dtObj.month) + \"_\" + str(dtObj.year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make grid\n",
    "st1 = datetime.now() \n",
    "\n",
    "pointfeatExtent = shp.Reader(pointfeat)\n",
    "\n",
    "xmin = pointfeatExtent.bbox[0]\n",
    "xmax = pointfeatExtent.bbox[2]\n",
    "ymin = pointfeatExtent.bbox[1]\n",
    "ymax = pointfeatExtent.bbox[3]\n",
    "\n",
    "makeGrid(polyfeat,xmin,xmax,ymin,ymax,gridHeight,gridWidth)\n",
    "\n",
    "percLst.append(['make grid', datetime.now() - st1 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the shapefile of polygons and convert it to shapely polygon objects\n",
    "st2 = datetime.now() \n",
    "\n",
    "polygons_sf = shp.Reader(polyfeat)\n",
    "polygon_shapes = polygons_sf.shapes()\n",
    "polygon_points = [q.points for q in polygon_shapes ]\n",
    "polygons = [Polygon(q) for q in polygon_points]\n",
    "poly_records = polygons_sf.records()\n",
    "\n",
    "percLst.append( ['load poly shp', datetime.now() - st2 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the shapefile of points and convert it to shapely point objects\n",
    "st3 = datetime.now() \n",
    "\n",
    "points_sf = shp.Reader(pointfeat)\n",
    "pntRecords = points_sf.shapeRecords()\n",
    "point_coords = [q.shape.points[0] for q in pntRecords ]\n",
    "points = [Point(q.shape.points[0]) for q in pntRecords ]\n",
    "\n",
    "percLst.append( ['load pnt shp', datetime.now() - st3 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C structure tally dictionaries\n",
    "st4 = datetime.now() \n",
    "\n",
    "GRIDdict = {}\n",
    "subGRIDdict = {}\n",
    "VIIRSdict = {}\n",
    "VIIRSdictDay = {}\n",
    "uDates = {}\n",
    "\n",
    "#select which column is the date column\n",
    "for i in pntRecords:\n",
    "    mnthYR = mnthYearChange(i.record[dateColNum])\n",
    "    uDate = i.record[dateColNum]\n",
    "    \n",
    "    #add keys (monthYear) to VIIRSdict & GRIDdict\n",
    "    if mnthYR in VIIRSdict:\n",
    "        VIIRSdict[mnthYR].append(i)\n",
    "    else:\n",
    "        VIIRSdict[mnthYR] = []\n",
    "        VIIRSdict[mnthYR].append(i) #key: monthYear, value: shape and attributes\n",
    "        \n",
    "    if uDate in VIIRSdictDay:\n",
    "        VIIRSdictDay[uDate].append(i)\n",
    "    else:\n",
    "        VIIRSdictDay[uDate] = []\n",
    "        VIIRSdictDay[uDate].append(i) #key: date, value: shape and attributes\n",
    "        \n",
    "        \n",
    "    GRIDdict[mnthYR] = None\n",
    "    uDates[uDate] = None #save for later for unique day count\n",
    "    \n",
    "\n",
    "    \n",
    "for i in poly_records: #fill subGRIDdict.  \n",
    "    subGRIDdict[i[0]] = None ##key= GRIDID, value= {GRIDid:0...    looks like {0:0, 1:0, 2:0 ...\n",
    "\n",
    "for key in GRIDdict:  #fill GRIDdict. \n",
    "    GRIDdict[key] = dict(subGRIDdict)  #key= 8_2012  value=  copies of subGRIDdict  \n",
    "    \n",
    "percLst.append( ['struc dicts months', datetime.now() - st4 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D Build a spatial index based on the bounding boxes of the polygons\n",
    "st5 = datetime.now() \n",
    "\n",
    "idx = index.Index()\n",
    "[ idx.insert(i, polygon_shapes[i].bbox) for i in range(len(polygon_shapes)) ]\n",
    "\n",
    "percLst.append( ['months indx', datetime.now() - st5 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[117.69496, 27.32167]\n",
      "POINT (117.69496 27.32167)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itclunie/anaconda/envs/TestEnv/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2918: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#actual points in grid cells matching, for months\n",
    "st6 = datetime.now() \n",
    "\n",
    "countr=0\n",
    "for key in VIIRSdict:\n",
    "    tallyHO = []\n",
    "    \n",
    "    for q in VIIRSdict[key]:\n",
    "        print(q.shape.points[0])\n",
    "        print(Point(q.shape.points[0]))\n",
    "        sys.exit()\n",
    "        \n",
    "    point_coords = [ q.shape.points[0] for q in VIIRSdict[key] ]\n",
    "    points = [ Point(q.shape.points[0]) for q in VIIRSdict[key] ]    \n",
    "    \n",
    "    for i in range(len(VIIRSdict[key])): #Iterate through each point\n",
    "\n",
    "        #Iterate only through the bounding boxes which contain the point. Verify that point is within the polygon itself not just the bounding box        \n",
    "        for j in idx.intersection(point_coords[i]):\n",
    "            \n",
    "            #Verify that point is within the polygon itself not just the bounding box\n",
    "            if points[i].within(polygons[j]):       \n",
    "                tallyHO.append(poly_records[j][0]) \n",
    "                break \n",
    "\n",
    "    resultDict = dict([ (i,tallyHO.count(i)) for i in set(tallyHO) ])\n",
    "\n",
    "    for rkey in resultDict:\n",
    "        GRIDdict[key][rkey] = resultDict[rkey] \n",
    "            \n",
    "    countr += 1\n",
    "    print( countr, len( VIIRSdict.keys() ) )\n",
    "    \n",
    "percLst.append( ['pnts in cells months', datetime.now() - st6 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove empty rows (ie empty grid squares), pick out hexes of interest, add centroids\n",
    "st7 = datetime.now() \n",
    "\n",
    "dfClean = pd.DataFrame.from_dict(GRIDdict, orient='columns', dtype=None) #the dataframe is the grid \n",
    "dfClean['X'] = None\n",
    "dfClean['Y'] = None\n",
    "\n",
    "dropLst = []\n",
    "for i in range(len(dfClean)):\n",
    "    row = dfClean.iloc[i]    \n",
    "    \n",
    "    if row.count() >= gridCutoff:  #user input        \n",
    "        centroid = polygons[i].centroid\n",
    "        cX = centroid.coords[0][0]\n",
    "        cY = centroid.coords[0][1]\n",
    "        dfClean.at[i,'X'] = cX\n",
    "        dfClean.at[i,'Y'] = cY\n",
    "    else:\n",
    "        dropLst.append(i)\n",
    "\n",
    "    if i % 50000 == 0:\n",
    "        print( i, len(dfClean) )\n",
    "    \n",
    "    \n",
    "df = dfClean.drop(dropLst)\n",
    "\n",
    "percLst.append( ['df clean', datetime.now() - st7 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st8 = datetime.now() \n",
    "\n",
    "intrstDict = {}    \n",
    "for i in df.index: #fill subGRIDdict.  \n",
    "    intrstDict[i] = None ##key= GRIDID, value= {GRIDid:0...    looks like {0:0, 1:0, 2:0 ...\n",
    "\n",
    "for key in uDates:  #fill GRIDdict. \n",
    "    uDates[key] = dict(intrstDict)  #key= 8/1/2012  value=  copies of intrstDict  \n",
    "    \n",
    "# for key in uDates:\n",
    "#     print(key, uDates[key])\n",
    "#     break\n",
    "\n",
    "percLst.append( ['days struc dicts', datetime.now() - st8 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st9 = datetime.now() \n",
    "\n",
    "idx2 = index.Index()\n",
    "[ idx2.insert(i, polygon_shapes[i].bbox) for i in intrstDict.keys() ]  #make index with only those polygons of interest\n",
    "\n",
    "percLst.append( ['days indx', datetime.now() - st9 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actual points in grid cells matching for days\n",
    "st10 = datetime.now() \n",
    "\n",
    "countr=0\n",
    "for key in VIIRSdictDay:\n",
    "    tallyHO = []\n",
    "    point_coords = [ q.shape.points[0] for q in VIIRSdictDay[key] ]\n",
    "    points = [ Point(q.shape.points[0]) for q in VIIRSdictDay[key] ]    \n",
    "    \n",
    "        \n",
    "    for i in range(len(VIIRSdictDay[key])): #Iterate through each point\n",
    "\n",
    "        #Iterate only through the bounding boxes which contain the point. Verify that point is within the polygon itself not just the bounding box        \n",
    "        for j in idx2.intersection(point_coords[i]):\n",
    "            \n",
    "            #Verify that point is within the polygon itself not just the bounding box\n",
    "            if points[i].within(polygons[j]):       \n",
    "                tallyHO.append(poly_records[j][0]) \n",
    "                break \n",
    "\n",
    "    resultDict = dict([ (i,tallyHO.count(i)) for i in set(tallyHO) ])\n",
    "\n",
    "    for rkey in resultDict:\n",
    "        uDates[key][rkey] = resultDict[rkey] \n",
    "            \n",
    "    countr += 1\n",
    "    print( countr, len( VIIRSdictDay.keys() ) )\n",
    "    \n",
    "percLst.append( ['pnts in cells days', datetime.now() - st10 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st11 = datetime.now() \n",
    "\n",
    "dfDays = pd.DataFrame.from_dict(uDates, orient='columns', dtype=None) #the dataframe is the grid \n",
    "dfDays['gID'] = dfDays.index\n",
    "df['uniqueDays'] = None\n",
    "\n",
    "percLst.append( ['days df', datetime.now() - st11 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st12 = datetime.now() \n",
    "\n",
    "for i in range(len(dfDays)):  #get count of unique days, match back into main df\n",
    "    row = dfDays.iloc[i] \n",
    "    gridID = row['gID']\n",
    "    gridCount = row.count() - 1  #minus 1 for the gID column\n",
    "    df.at[gridID,'uniqueDays'] = gridCount\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(i, len(dfDays))\n",
    "        \n",
    "percLst.append( ['days u count', datetime.now() - st12 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write output files\n",
    "st13 = datetime.now() \n",
    "\n",
    "\n",
    "df.to_csv(outPath + 'industryFindR_wide.csv')\n",
    "df['GRIDid'] = df.index\n",
    "melted = df.melt(id_vars=['GRIDid','X','Y','uniqueDays']) \n",
    "melted.to_csv(outPath + 'industryFindR_long.csv')\n",
    "\n",
    "percLst.append( ['write output', datetime.now() - st13 ])\n",
    "total = datetime.now() - startTime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in percLst:\n",
    "    print(round( (j/total)*100, 3), i )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
